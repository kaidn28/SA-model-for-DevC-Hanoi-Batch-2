{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"predict.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"TRGYBJupTBVs"},"source":["import torch\n","import torch.nn as nn\n","import pickle \n","import re\n","import numpy as np\n","import pandas as pd\n","from gensim.models.phrases import Phrases, Phraser\n","from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fAazki9WcB5I","executionInfo":{"status":"error","timestamp":1606143534503,"user_tz":-420,"elapsed":5413,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}},"outputId":"9aab6eac-2534-441a-f4c0-358ffd5937eb","colab":{"base_uri":"https://localhost:8080/","height":539}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"QrlN7bfDc-IW","executionInfo":{"status":"aborted","timestamp":1606143534507,"user_tz":-420,"elapsed":76,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["#model with 3 part: embedding layer -> stack lstms -> fc layers with softmax classifier\n","class SentimentLSTM(nn.Module):\n","    \"\"\"\n","    The RNN model that will be used to perform Sentiment analysis.\n","    \"\"\"\n","\n","    def __init__(self, output_size, embedding_dim, hidden_dim, n_layers, n_cell, drop_prob = 0.2):\n","        \"\"\"\n","        Initialize the model by setting up the layers.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        \n","        #embedding layer\n","        self.embedding = nn.Embedding.from_pretrained(emb_matrix, freeze = False)\n","        # LSTM layers\n","        self.lstm = nn.LSTM(input_size = embedding_dim,hidden_size = hidden_dim, num_layers = n_layers, batch_first = True, dropout = drop_prob)\n","        \n","        # dropout layer\n","        self.dropout = nn.Dropout(0.3)\n","        \n","        # linear and sigmoid layers \n","        self.fc = nn.Linear(hidden_dim, output_size)\n","        #self.fc1 = nn.Linear(hidden_dim, hidden_dim*2)\n","        #self.relu1 = nn.LeakyReLU()\n","        #self.fc2 = nn.Linear(hidden_dim*2, output_size)\n","      \n","        self.softmax = nn.Softmax(dim = 1)\n","        \n","\n","    def forward(self, x, hidden):\n","        \"\"\"\n","        Perform a forward pass of our model on some input and hidden state.\n","        \"\"\"\n","        batch_size = x.size(0)\n","        #print(x)\n","        # embeddings and lstm_out\n","\n","        embeds = self.embedding(x)\n","        embeds = embeds.float()\n","        #print(type(embeds))\n","        #print(embeds)\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","        #print(lstm_out.shape)\n","        #stack up lstm outputs\n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n","        #print(lstm_out.shape)\n","        \n","        # dropout and fully-connected layer\n","        out = self.dropout(lstm_out)\n","        #print(out.shape)\n","        #out = lstm_out[:, -1, :]\n","        #print(out.shape)\n","        out = self.fc(out)\n","        #out = self.fc1(out)\n","        #out = self.fc2(out)\n","        #print(out.shape)\n","        # sigmoid function\n","        #print(out.shape)\n","        out = out.contiguous().view(batch_size, -1, self.output_size)\n","        out = out[:, -1, :]\n","        out = self.softmax(out)\n","        # reshape to be batch_size first\n","        #print(out.shape)\n","        #out = out.view(batch_size,n_cell, -1)\n","        #print(out.shape)\n","        #out = out[:, -1] # get last batch of labels\n","        #print(out.shape)\n","        # return last sigmoid output and hidden state\n","\n","        return out, hidden\n","    \n","    \n","    def init_hidden(self, batch_size, train_on_gpu = False):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","        \n","        if (train_on_gpu):\n","            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n","                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n","        else:\n","            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().float(),\n","                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().float())\n","        \n","        return hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEmw9XRtTMpZ","executionInfo":{"status":"aborted","timestamp":1606143534507,"user_tz":-420,"elapsed":66,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["#phraser for word2vec\n","bigram = Phraser.load(\"/content/drive/My Drive/DevC/saves/bigram.pkl\")\n","\n","#word2idx\n","word2idx = pickle.load(open(\"/content/drive/My Drive/DevC/saves/word2idx.pickle\", \"rb\"))\n","print(len(word2idx))\n","#predict model:\n","emb_matrix = torch.zeros((len(word2idx)+1,200))\n","model = SentimentLSTM(output_size= 3, embedding_dim=200, hidden_dim= 128, n_layers= 2, n_cell = 50, drop_prob = 0.2)\n","state = torch.load('/content/drive/My Drive/DevC/saves/model_state.pt')\n","model.load_state_dict(state)\n","\n","#process materials:\n","ev_path = \"/content/drive/My Drive/DevC/process materials/Englishwords.xlsx\"\n","sf_path = \"/content/drive/My Drive/DevC/process materials/Shortform.xlsx\"\n","englishwords = pd.read_excel(ev_path, index_col= \"English\")\n","shortform = pd.read_excel(sf_path, index_col= \"Short\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rowndz6fg4-7","executionInfo":{"status":"aborted","timestamp":1606143534509,"user_tz":-420,"elapsed":63,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["def deEmojify(text):\n","    regrex_pattern = re.compile(pattern = \"[\"\n","        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                           \"]+\", flags = re.UNICODE)\n","    return regrex_pattern.sub(r'',text)\n","def preprocess(text):\n","  #bỏ tag html và emoji\n","  text = re.sub('<[^>]*>', '', text)\n","  text = deEmojify(text)\n","\n","  #thay chữ cái viết hoa thành viết thường\n","  text = text.lower()\n","\n","  #xóa dấu ngắt câu, xóa link và các chữ có chứa chữ số\n","  clean_text = []\n","  punc_list = '.,;:?!\\|/&@`~()-_@#$%^*\\'\\\"'\n","  for w in (text.split()):\n","    if \"http\" in w:\n","      continue\n","    clean_text.append(w)\n","  text = ' '.join(clean_text)\n","  for punc in punc_list:\n","    text = text.replace(punc, ' ')\n","\n","  #xóa bỏ các chữ cái lặp liên tiếp nhau (đỉnhhhhhhhhhh, vipppppppppppppppp)\n","  length = len(text)\n","  char = 0\n","  while char <length-1:\n","    if text[char] == text[char+1]:\n","      text = text[:char]+text[char+1:]\n","      #print(text)\n","      length-=1\n","      continue\n","    char+=1  \n","  numbers = [\"không\", \"một\", \"hai\", \"ba\", \"bốn\", \"năm\", \"sáu\", \"bảy\", \"tám\", \"chín\"]\n","  #chuyển đổi các từ tiếng anh và viết tắt thông dụng sang tiếng Việt chuẩn:\n","  text_split = text.split()\n","  for i, w in enumerate(text_split):\n","    if w in englishwords.index:\n","      text_split[i] = str(englishwords.loc[w, \"Vietnamese\"])\n","    if w in shortform.index:\n","      text_split[i] = str(shortform.loc[w, \"Long\"])\n","    if w.isdigit():\n","      text_split[i] = ' '.join([numbers[int(c)] for c in w]) \n","  text = ' '.join(text_split)\n","\n","  #loại bỏ tất cả các kí tự đặc biệt còn lại\n","  digits_and_characters = 'aăâbcdđeêfghijklmnoôơpqrstuưvxywzáàảãạắằẳẵặấầẩẫậéèẻẽẹếềểễệíìỉĩịóòỏõọốồổỗộớờởỡợúùủũụứừửữựýỳỷỹỵ0123456789 '\n","  text = ''.join([i for i in text if i in digits_and_characters])\n","  return text\n","\n","#split all sentences in corpus\n","def splitCorpus(corpus):\n","  t = [sentence.split() for sentence in corpus]\n","  return t\n","#join all splited sentences to a big text document\n","def joinAllSplit(tokenized_sentences):\n","  sentences = [' '.join(sentence) for sentence in tokenized_sentences]\n","  return ' '.join(sentences)\n","\n","#below function get performe preprocessing and remove unknown words\n","def prepros(sentences):\n","  new_sentences = [preprocess(sentence) for sentence in sentences]\n","  splitted_sentences = splitCorpus(new_sentences)\n","  new = []\n","  for sentence in bigram[splitted_sentences]:\n","    new_sentence = ' '.join([word for word in sentence if word in word2idx.keys()])\n","    new.append(new_sentence)\n","  return new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nv6UGdix3mGB","executionInfo":{"status":"aborted","timestamp":1606143534510,"user_tz":-420,"elapsed":61,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["#convert words to numbers\n","def sentenceToInt(sentences):\n","  #print(sentences)\n","  int_sentences = []\n","  for sentence in sentences:\n","    int_sentence = [word2idx[word] for word in sentence.split()]   \n","    int_sentences.append(int_sentence)\n","  return int_sentences\n","\n","#pad int_sentences to the feature_leng\n","def padFeature(sentences, feature_leng = 50):\n","  smatrix = np.zeros((len(sentences), feature_leng))\n","  for sen_index, sentence in enumerate(sentences):\n","    padding = max(0, feature_leng - len(sentence))\n","    for word_index in range(feature_leng):\n","      if word_index < padding:\n","        smatrix[sen_index, word_index] = 0\n","      else:\n","        smatrix[sen_index, word_index] = sentence[word_index-padding]\n","  return smatrix\n","\n","def process(sentences, feature_leng = 50):\n","  int_sentences = sentenceToInt(sentences)\n","  feature_matrix = padFeature(int_sentences, feature_leng = 50)\n","  return feature_matrix\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCgsOb4kZo4q","executionInfo":{"status":"aborted","timestamp":1606143534511,"user_tz":-420,"elapsed":58,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["def predict(net, comments, sequence_length=50, train_on_gpu = False):\n","    \n","    net.eval()\n","    #preprocess:\n","    cleaned_comments = prepros(comments)\n","    #print(cleaned_comments)\n","    #process:\n","    features = process(cleaned_comments)\n","    #print(features)\n","    feature_tensor = torch.from_numpy(features)\n","    feature_tensor = feature_tensor.type(torch.LongTensor)\n","    batch_size = feature_tensor.size(0)\n","    #print(feature_tensor.size(0))\n","    # initialize hidden state\n","    h = net.init_hidden(batch_size)\n","    \n","    if(train_on_gpu):\n","        feature_tensor = feature_tensor.cuda()\n","    \n","    # get the output from the model\n","    output, h = net(feature_tensor, h)\n","    #print(output.squeeze())\n","    # convert output probabilities to prediction\n","    pred = torch.argmax(output, dim = 1)\n","    # printing output value, before rounding\n","    #print(pred)\n","    return pred, output, cleaned_comments"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WbL0oP3-SCS","executionInfo":{"status":"aborted","timestamp":1606143534512,"user_tz":-420,"elapsed":50,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["test = pd.read_csv('/content/drive/My Drive/DevC/datasets/comments.csv')\n","print(test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-q1sYkGB6Gs","executionInfo":{"status":"aborted","timestamp":1606143534514,"user_tz":-420,"elapsed":46,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["comments = test.Comment.to_list()\n","print(comments)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0U1xmCs_CCA1","executionInfo":{"status":"aborted","timestamp":1606143534516,"user_tz":-420,"elapsed":44,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["pred, output, cleaned_comments = predict(model, comments= [\"bền, tốt\"], sequence_length= 50, train_on_gpu= False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYrcXzFJCZLH","executionInfo":{"status":"aborted","timestamp":1606143534518,"user_tz":-420,"elapsed":41,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["list_pred = pred.tolist()\n","output = (torch.round(output*100))/100\n","list_output = output.tolist()\n","for i, n in enumerate(list_pred):\n","  if n == 0:\n","    list_pred[i] = '=>  tiêu cực'\n","  elif n == 1:\n","    list_pred[i] = '=>  trung lập'\n","  else:\n","    list_pred[i] = \"=>  tích cực\"\n","print(list_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8BvSR3EtKqs","executionInfo":{"status":"aborted","timestamp":1606143534519,"user_tz":-420,"elapsed":35,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["for i in range (1):\n","  print(comments[i][:50], \"=>\", cleaned_comments[i][:], list_pred[i], list_output[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m5iWx4XeuDeU","executionInfo":{"status":"aborted","timestamp":1606143534520,"user_tz":-420,"elapsed":32,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":["pred, output, _ = predict(model, [\"bền, tốt\"])\n","print(pred, output, _)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TgmgXdNEdHpb","executionInfo":{"status":"aborted","timestamp":1606143534520,"user_tz":-420,"elapsed":28,"user":{"displayName":"Nguyễn Trân","photoUrl":"","userId":"08428657414001975731"}}},"source":[""],"execution_count":null,"outputs":[]}]}